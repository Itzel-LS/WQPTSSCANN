{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Transformations for AlexNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224), # se ajusta la imagen a 224x224 pixeles\n",
    "    transforms.CenterCrop(224), # se corto del centro a 224\n",
    "    transforms.ToTensor(), # Convierte a imagen PIL (Python Imaging Library) en un tensor de PyTorch\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # se normalizan los valores estandar RGB\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a Class Based on the Folder Name\"\n",
    "\n",
    "# Data\n",
    "data = 'C:/Users/itz_l/Desktop/luzAro/datasets/'\n",
    "# Create an ImageFolder for Your Dataset\n",
    "# Automatically reads the folders and considers that the folder name corresponds to the class\n",
    "dataset = ImageFolder(root=data, transform=transform)\n",
    "\n",
    "# Get Image Indices for Each Class\"\n",
    "# I try to ensure that the same number of images is used for training\n",
    "# This way, I ensure that all classes are included and none are left out\n",
    "indices = {label: np.where(np.array(dataset.targets) == label)[0] for label in range(len(dataset.classes))}\n",
    "\n",
    "# Dividir los índices para cada clase en entrenamiento y prueba\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "for label, idx in indices.items():\n",
    "    np.random.shuffle(idx)\n",
    "    train_size = int(0.9 * len(idx))\n",
    "    train_indices.extend(idx[:train_size])\n",
    "    test_indices.extend(idx[train_size:])\n",
    "\n",
    "# Create Training and Testing Subsets with the Obtained Indices\n",
    "train_data = Subset(dataset, train_indices)\n",
    "test_data = Subset(dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders for the Training and Testing Sets\n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=50, shuffle=False) \n",
    "\n",
    "# Check the Number of Samples in Each Set\n",
    "print(f\"Training Samples: {len(train_data)}\")\n",
    "print(f\"Validation Samples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Cache Directory\n",
    "cache_dir = os.path.expanduser('~/.cache/torch/hub/checkpoints')\n",
    "\n",
    "# Delete the Cache Directory if It Exists\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(f\"Cache Directory Deleted: {cache_dir}\")\n",
    "else:\n",
    "    print(f\"Cache Directory Not Found at: {cache_dir}\")\n",
    "# Descargar modelo preentrenado AlexNet\n",
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Final Layer with a New Classifier\n",
    "alexnet.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(alexnet.classifier[6].in_features, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate metrics\n",
    "def calculate_metrics(all_labels, all_preds):\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    return accuracy, precision, recall, f1, conf_matrix\n",
    "\n",
    "# Function to Calculate Probabilities, Predictions, and True Labels\n",
    "def calculate_probs_and_preds(model, dataloader, device):\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Probabilities by class\n",
    "            _, predicted = torch.max(outputs, 1)   # Prediction class\n",
    "            \n",
    "            # Convert to NumPy Arrays and Extend Lists\n",
    "            probs_np = probs.cpu().numpy()\n",
    "            preds_np = predicted.cpu().numpy()\n",
    "            all_probs.extend(probs_np)\n",
    "            all_preds.extend(preds_np)\n",
    "            \n",
    "            # Capturar etiquetas verdaderas\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_probs), np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# Define the Model, Optimizer, and Loss Function\n",
    "num_epochs = 50\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = alexnet.to(device)\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.000005)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in range(num_epochs):\n",
    "    alexnet.train()  # Modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    all_preds_train = []\n",
    "    all_labels_train = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Collect predictions and labels for training phase metrics\n",
    "        all_preds_train.extend(predicted.cpu().numpy())\n",
    "        all_labels_train.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Calculate Metrics for the Training Phase\n",
    "    accuracy_train, precision_train, recall_train, f1_train, _ = calculate_metrics(all_labels_train, all_preds_train)\n",
    "    print(f\"Training Metrics: Accuracy: {accuracy_train:.4f}, Precision: {precision_train:.4f}, Recall: {recall_train:.4f}, F1-score: {f1_train:.4f}\")\n",
    "\n",
    "    # Model Evaluation on the Validation Set\n",
    "    alexnet.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds_val = []\n",
    "    all_labels_val = []\n",
    "    all_probs_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = alexnet(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Probabilities by class\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Add Probabilities and Predictions to the Validation Set\n",
    "            all_probs_val.extend(probs.cpu().numpy())\n",
    "            all_preds_val.extend(predicted.cpu().numpy())\n",
    "            all_labels_val.extend(labels.cpu().numpy())\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "    epoch_val_acc = correct / total\n",
    "    val_loss_history.append(epoch_val_loss)\n",
    "    val_acc_history.append(epoch_val_acc)\n",
    "    print(f\"Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    # Metrics calculation to each validation phaase\n",
    "    accuracy_val, precision_val, recall_val, f1_val, _ = calculate_metrics(all_labels_val, all_preds_val)\n",
    "    print(f\"Validation Metrics: Accuracy: {accuracy_val:.4f}, Precision: {precision_val:.4f}, Recall: {recall_val:.4f}, F1-score: {f1_val:.4f}\")\n",
    "\n",
    "# OVerall metrics calculation\n",
    "accuracy, precision, recall, f1, conf_matrix = calculate_metrics(all_labels_val, all_preds_val)\n",
    "print(f\"\\nOverall Metrics on Validation Set:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all_probs_val to a NumPy array if it isn't already\n",
    "all_probs_val = np.array(all_probs_val)\n",
    "\n",
    "# Obtain Binary Labels for Each Class\n",
    "y_true = np.array(all_labels_val)\n",
    "y_score = np.array(all_probs_val)\n",
    "\n",
    "# Class names\n",
    "class_names = [\"Class: 'High'\", \"Class: 'Medium'\", \"Class: 'Low'\"]\n",
    "\n",
    "# Calculate the ROC Curve and Area Under the Curve (AUC) for Each Class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "num_classes = len(class_names)  # Número de clases\n",
    "\n",
    "# Binarize the True Labels\n",
    "y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    # ROC for each class\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Calculate the overall ROC curve for all classes\"\n",
    "# Interpolate FPR and TPR to ensure each class has the same number of points\"\n",
    "all_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= num_classes\n",
    "mean_auc = auc(all_fpr, mean_tpr)\n",
    "\n",
    "# Crear figura y subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Graficar las curvas ROC de cada clase en el primer subplot\n",
    "colors = ['red', 'orange', 'green']  # Colores para las curvas ROC de cada clase\n",
    "markers = ['o', 'x', '+']  # Marcadores para las curvas ROC de cada clase\n",
    "linestyles = ['-', '-', '-']  # Estilos de línea para las curvas ROC de cada clase\n",
    "linewidths = [2, 1.5, 1]  # Grosor de las líneas para cada clase\n",
    "\n",
    "for i, color, marker, linestyle, lw in zip(range(num_classes), colors, markers, linestyles, linewidths):\n",
    "    axes[0].plot(fpr[i], tpr[i], linestyle=linestyle, marker=marker, color=color, \n",
    "                 linewidth=lw, label=f'{class_names[i]} (AUC = {roc_auc[i]:.4f})')\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=17)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=17)\n",
    "axes[0].set_title('')\n",
    "axes[0].legend(loc=\"lower right\",  fontsize='large')\n",
    "axes[0].text(0.5, -0.2, '(a)', ha='center', va='center', transform=axes[0].transAxes, fontsize=17)\n",
    "\n",
    "# Graficar la curva ROC promedio en el segundo subplot\n",
    "axes[1].plot(all_fpr, mean_tpr, color='black', linestyle='--', lw=2, label=f'Overall (AUC = {mean_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=17)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=17)\n",
    "axes[1].set_title('')\n",
    "axes[1].legend(loc=\"lower right\",  fontsize='large')\n",
    "axes[1].text(0.5, -0.2, '(b)', ha='center', va='center', transform=axes[1].transAxes, fontsize=17)\n",
    "# Mostrar la figura con los subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = [\"High\", \"Medium\", \"Low\"]\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "# Normalized Confution matrix\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Greens\", fmt=\"d\", cbar=False, ax=axes[1], \n",
    "            linewidths=1, xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 18})\n",
    "axes[1].set_title('', fontsize=25)\n",
    "axes[1].set_xlabel('Predicted label', fontsize=22)\n",
    "axes[1].set_ylabel('True label', fontsize=22)\n",
    "axes[1].tick_params(axis='both', labelsize=18)\n",
    "\n",
    "# Unnormalized Confution matrix\n",
    "sns.heatmap(norm_conf_matrix, annot=True, cmap=\"Greens\", fmt=\".2f\", cbar=False, ax=axes[0], \n",
    "            linewidths=1, xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 20})\n",
    "axes[0].set_title('', fontsize=25)\n",
    "axes[0].set_xlabel('Predicted label', fontsize=22)\n",
    "axes[0].set_ylabel('True label', fontsize=22)\n",
    "axes[0].tick_params(axis='both', labelsize=18)  \n",
    "fig.text(0.27, 0.08, '(a)', fontsize=22, ha='center')\n",
    "fig.text(0.77, 0.08, '(b)', fontsize=22, ha='center')\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup style\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Create Figure\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Accuracy Plot\n",
    "axs[0].plot(range(1, len(train_acc_history) + 1), train_acc_history, label='Training', linewidth=1.5, color='blue')\n",
    "axs[0].plot(range(1, len(val_acc_history) + 1), val_acc_history, label='Validation', linewidth=1.5, linestyle='--', color='black')\n",
    "axs[0].set_xlabel('Epoch', fontsize=16)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=16)\n",
    "axs[0].legend(fontsize=17)\n",
    "axs[0].set_title('')\n",
    "axs[0].tick_params(axis='both', labelsize=15)  \n",
    "\n",
    "# Loss Plot\n",
    "axs[1].plot(range(1, len(train_loss_history) + 1), train_loss_history, label='Training', linewidth=1.5, color='blue')\n",
    "axs[1].plot(range(1, len(val_loss_history) + 1), val_loss_history, label='Validation', linewidth=1.5, \n",
    "            linestyle='--', color='black')\n",
    "axs[1].set_xlabel('Epoch', fontsize=16)\n",
    "axs[1].set_ylabel('Loss', fontsize=16)\n",
    "axs[1].legend(fontsize=17)\n",
    "axs[1].set_title('')\n",
    "axs[1].tick_params(axis='both', labelsize=15)  \n",
    "fig.text(0.29, 0.09, '(a)', fontsize=18, ha='center')\n",
    "fig.text(0.78, 0.09, '(b)', fontsize=18, ha='center')\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Random Index in the Test Set\n",
    "random_idx = random.randint(0, len(test_loader.dataset) - 1)\n",
    "sample_image, sample_label = test_loader.dataset[random_idx]\n",
    "sample_image = sample_image.unsqueeze(0)  # Añadir una dimensión para el batch\n",
    "\n",
    "# Obtain the Feature Maps\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Initialize a Dictionary to Store the Feature Maps\n",
    "features = {}\n",
    "alexnet.features[0].register_forward_hook(get_features('conv1'))\n",
    "alexnet.features[3].register_forward_hook(get_features('conv2'))\n",
    "alexnet.features[6].register_forward_hook(get_features('conv3'))\n",
    "alexnet.features[8].register_forward_hook(get_features('conv4'))\n",
    "alexnet.features[10].register_forward_hook(get_features('conv5'))\n",
    "\n",
    "# Pass the Image Through the Model\n",
    "alexnet(sample_image)\n",
    "\n",
    "# Function to Find the Index of the Filter with the Strongest Activations\n",
    "def get_strongest_activation(feature_map):\n",
    "    activations = torch.sum(torch.abs(feature_map), dim=[2, 3])\n",
    "    strongest_filter_idx = torch.argmax(activations, dim=1).item()\n",
    "    return strongest_filter_idx\n",
    "\n",
    "# Collect the Activations from Each Convolutional Layer\n",
    "activations = [sample_image.squeeze(0)]  # Comenzar con la imagen original\n",
    "conv_layers = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5']\n",
    "for layer_name in conv_layers:\n",
    "    strongest_filter_idx = get_strongest_activation(features[layer_name])\n",
    "    activation_map = features[layer_name][0, strongest_filter_idx]\n",
    "    activations.append(activation_map)\n",
    "\n",
    "#Visualize the Activations of Each Convolutional Layer\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Limit to a Maximum of 6 Subplots\n",
    "num_subplots = min(len(activations), 6)\n",
    "letters = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)']  \n",
    "\n",
    "for i in range(num_subplots):\n",
    "    activation_map = activations[i].cpu().numpy()\n",
    "    ax = plt.subplot(2, 3, i + 1) \n",
    "\n",
    "    if i == 0:\n",
    "        \n",
    "        ax.imshow(activation_map.transpose(1, 2, 0), cmap='gray') \n",
    "        title_text = 'Input Image'\n",
    "    else:\n",
    "        \n",
    "        ax.imshow(activation_map, cmap='gray')\n",
    "        title_text = f'Conv. Layer {i}: Random Freature Map'\n",
    "\n",
    "    \n",
    "    ax.set_xlabel(f'{letters[i]}', fontsize=18, labelpad=5)  \n",
    "    ax.set_title('') \n",
    "    ax.tick_params(axis='both', labelsize=17)  \n",
    "    ax.axis('on')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
